import pandas as pd
import numpy as np
import datetime

# -------------------------------------------------------------------
# Generic helpers
# -------------------------------------------------------------------

def is_blank(x):
    """
    Identifies blank values in the key fields.
    Returns True for blank / NA, False otherwise.
    """
    if pd.isna(x):
        return True
    if isinstance(x, str) and x.strip() == "":
        return True
    if isinstance(x, (np.datetime64, datetime.date)):
        # let pandas decide if this datetime-like is NA
        return pd.isna(x)
    return False


def nonblank_equal(a, b):
    return (not is_blank(a)) and (not is_blank(b)) and a == b


def nonblank_not_equal(a, b):
    return (not is_blank(a)) and (not is_blank(b)) and a != b


# -------------------------------------------------------------------
# DOB helpers
# -------------------------------------------------------------------

def dob_is_strict_match(dob1, dob2, dob_est1, dob_est2):
    """
    DOBs are considered a 'strict match' if:
    - both are non-blank
    - both are equal
    - neither is estimated (dob_est != 'Y')
    """
    if is_blank(dob1) or is_blank(dob2):
        return False
    if dob_est1 == "Y" or dob_est2 == "Y":
        return False
    if dob1 != dob2:
        return False
    return True


def dob_is_strict_not_match(dob1, dob2):
    """
    DOBs are considered a 'strict not match' if:
    - both are non-blank
    - they are not equal
    - NO consideration for estimation
    """
    if is_blank(dob1) or is_blank(dob2):
        return False
    return dob1 != dob2


# -------------------------------------------------------------------
# Strong match rules (0-6)
# -------------------------------------------------------------------

def match_rule(r1, r2):
    """
    Strong match rules 0–6.
    r1, r2 are tuples: (first_name, last_name, dob, ssn, dob_est_flag)
    """
    fn1, ln1, dob1, ssn1, dob_est1 = r1
    fn2, ln2, dob2, ssn2, dob_est2 = r2

    dob_match    = dob_is_strict_match(dob1, dob2, dob_est1, dob_est2)
    dob_ne_match = dob_is_strict_not_match(dob1, dob2)
    dob1_blank   = is_blank(dob1)
    dob2_blank   = is_blank(dob2)

    # Rule 0: FN= LN= DOB= SSN=
    if nonblank_equal(fn1, fn2) and nonblank_equal(ln1, ln2) \
       and dob_match and nonblank_equal(ssn1, ssn2):
        return 0

    # Rule 1: FN= LN= DOB- SSN=
    if nonblank_equal(fn1, fn2) and nonblank_equal(ln1, ln2) \
       and dob_ne_match and nonblank_equal(ssn1, ssn2):
        return 1

    # Rule 2: FN= LN- DOB= SSN=
    if nonblank_equal(fn1, fn2) and nonblank_not_equal(ln1, ln2) \
       and dob_match and nonblank_equal(ssn1, ssn2):
        return 2

    # Rule 3: FN- LN= DOB= SSN=
    if nonblank_not_equal(fn1, fn2) and nonblank_equal(ln1, ln2) \
       and dob_match and nonblank_equal(ssn1, ssn2):
        return 3

    # Rule 4: FN- LN= DOB blank SSN=
    if nonblank_not_equal(fn1, fn2) and nonblank_equal(ln1, ln2) \
       and (dob1_blank or dob2_blank) and nonblank_equal(ssn1, ssn2):
        return 4

    # Rule 5: FN= LN- DOB blank SSN=
    if nonblank_equal(fn1, fn2) and nonblank_not_equal(ln1, ln2) \
       and (dob1_blank or dob2_blank) and nonblank_equal(ssn1, ssn2):
        return 5

    # Rule 6: FN= LN= DOB blank SSN=
    if nonblank_equal(fn1, fn2) and nonblank_equal(ln1, ln2) \
       and (dob1_blank or dob2_blank) and nonblank_equal(ssn1, ssn2):
        return 6

    return None


# -------------------------------------------------------------------
# Likely match rules (7-12)
# -------------------------------------------------------------------

def likely_match_rule(r1, r2):
    """
    Likely match rules 7–12.
    r1, r2 are tuples: (first_name, last_name, dob, ssn, dob_est_flag)
    """
    fn1, ln1, dob1, ssn1, dob_est1 = r1
    fn2, ln2, dob2, ssn2, dob_est2 = r2

    dob_match    = dob_is_strict_match(dob1, dob2, dob_est1, dob_est2)
    dob_ne_match = dob_is_strict_not_match(dob1, dob2)

    # 7: FN= LN= DOB- SSN=
    if nonblank_equal(fn1, fn2) and nonblank_equal(ln1, ln2) \
       and dob_ne_match and nonblank_equal(ssn1, ssn2):
        return 7

    # 8: FN= LN- DOB= SSN=
    if nonblank_equal(fn1, fn2) and nonblank_not_equal(ln1, ln2) \
       and dob_match and nonblank_equal(ssn1, ssn2):
        return 8

    # 9: FN- LN= DOB= SSN blank
    if nonblank_not_equal(fn1, fn2) and nonblank_equal(ln1, ln2) \
       and dob_match and (is_blank(ssn1) or is_blank(ssn2)):
        return 9

    # 10: FN= LN- DOB= SSN blank
    if nonblank_equal(fn1, fn2) and nonblank_not_equal(ln1, ln2) \
       and dob_match and (is_blank(ssn1) or is_blank(ssn2)):
        return 10

    # 11: FN= LN= DOB- SSN blank
    if nonblank_equal(fn1, fn2) and nonblank_equal(ln1, ln2) \
       and dob_ne_match and (is_blank(ssn1) or is_blank(ssn2)):
        return 11

    # 12: FN- LN= DOB- SSN=
    if nonblank_not_equal(fn1, fn2) and nonblank_equal(ln1, ln2) \
       and dob_ne_match and nonblank_equal(ssn1, ssn2):
        return 12

    return None


# -------------------------------------------------------------------
# Relationship / address helpers for likely matches
# -------------------------------------------------------------------

allowed_relationships = [
    "Father-Adoptive", "Father-Biological", "Father-Unknown",
    "Mother-Adoptive", "Mother-Biological", "Mother-Unknown",
    "Guardian-Unknown", "Guardian-Legal", "Guardian-Non-Legal",
    "Guardian-Ad Litem", "Guardian-Court Ordered",
    "Sibling-Full", "Sibling-Maternal Half", "Sibling-Paternal Half",
]


def relatives_for_referral(df_rel, referral_id, relationship):
    """
    Return a list of (fn, ln, dob, ssn, dob_est) tuples for relatives
    in df_rel for that referral and relationship.
    """
    rel = df_rel[
        (df_rel["referral_id"] == referral_id) &
        (df_rel["relative_relationship"] == relationship)
    ].copy()

    if rel.empty:
        return []

    return list(
        zip(
            rel["relative_first_name"],
            rel["relative_last_name"],
            rel["relative_date_of_birth"],
            rel["relative_social_security_number"],
            rel["relative_date_of_birth_estimated"],
        )
    )


def primary_address_for_referral(df_add, referral_id):
    """
    Return (address_line_1, city, zip) for the 'Primary' address
    in the address table, or None if not found.
    """
    add = df_add[
        (df_add["Referral ID"] == referral_id) &
        (df_add["Address Type"].str.lower() == "primary")
    ]

    if add.empty:
        return None

    row = add.iloc[0]
    return (
        row.get("Address Line 1"),
        row.get("City"),
        row.get("Zip Code"),
    )


def confirm_likely_match(row1, row2, rule, df_rel, df_add):
    """
    Extra confirmation step for likely matches 7-12:

    1) If perp_relationship is in allowed_relationships:
       - look up relatives with that relationship for both referrals,
       - if any relative pair is a strong match (0-6) -> True.

    2) Otherwise, fall back to address comparison:
       - if primary address (line1 + city + zip) matches -> True.
    """
    relationship1 = row1.get("perp_relationship")
    relationship2 = row2.get("perp_relationship")

    # Relationship-based confirmation
    if (
        relationship1 == relationship2
        and relationship1 in allowed_relationships
        and df_rel is not None
    ):
        rels1 = relatives_for_referral(df_rel, row1["referral_id"], relationship1)
        rels2 = relatives_for_referral(df_rel, row2["referral_id"], relationship2)

        for r1 in rels1:
            for r2 in rels2:
                if match_rule(r1, r2) is not None:   # any strong rule 0-6
                    return True

    # Address-based confirmation
    if df_add is not None:
        addr1 = primary_address_for_referral(df_add, row1["referral_id"])
        addr2 = primary_address_for_referral(df_add, row2["referral_id"])
        if addr1 and addr2 and addr1 == addr2:
            return True

    return False


# -------------------------------------------------------------------
# Main function: add perp_reoccurrence_flag(Y/N)
# -------------------------------------------------------------------

def add_perp_reoccurrence_flag(df, df_rel=None, df_add=None):
    """
    For each unique (long_person_id, person_id, referral_id) row in df,
    set perp_reoccurrence_flag='Y' if the same perpetrator appears in
    another referral for that (long_person_id, person_id) based on:

    - Strong rules 0-6 on perpetrator FN/LN/DOB/SSN (+ DOB est flag)
    - OR likely rules 7-12 plus relationship / address confirmation.
    """
    df = df.copy()
    df["perp_reoccurrence_flag"] = "N"

    group_cols = ["long_person_id", "person_id"]
    if not all(col in df.columns for col in group_cols):
        raise ValueError(f"df must contain columns {group_cols}")

    matched_idx = set()

    # Work within each longitudinal person + victim person
    for _, grp in df.groupby(group_cols):
        idxs = list(grp.index)
        if len(idxs) < 2:
            continue

        for i in range(len(idxs)):
            for j in range(i + 1, len(idxs)):
                idx_i = idxs[i]
                idx_j = idxs[j]

                row_i = df.loc[idx_i]
                row_j = df.loc[idx_j]

                r1 = (
                    row_i["perp_first_name"],
                    row_i["perp_last_name"],
                    row_i["perp_date_of_birth"],
                    row_i["perp_social_security_number"],
                    row_i["perp_date_of_birth_estimated"],
                )
                r2 = (
                    row_j["perp_first_name"],
                    row_j["perp_last_name"],
                    row_j["perp_date_of_birth"],
                    row_j["perp_social_security_number"],
                    row_j["perp_date_of_birth_estimated"],
                )

                # Step 1: strong match?
                rule = match_rule(r1, r2)

                if rule is not None:
                    matched_idx.add(idx_i)
                    matched_idx.add(idx_j)
                else:
                    # Step 2: likely match + extra checks
                    lk_rule = likely_match_rule(r1, r2)
                    if lk_rule is not None:
                        if confirm_likely_match(row_i, row_j, lk_rule, df_rel, df_add):
                            matched_idx.add(idx_i)
                            matched_idx.add(idx_j)

    if matched_idx:
        df.loc[list(matched_idx), "perp_reoccurrence_flag"] = "Y"

    return df


# -------------------------------------------------------------------
# EXTRA: derived flags for summaries
#   - perp_in_child_family (Y/N, based on relationship)
#   - address_exact_match_flag (Y/N, based on primary address)
# -------------------------------------------------------------------

def add_perp_in_family_and_address_flags(df_with_flag, df_add):
    df = df_with_flag.copy()

    # 1) Perp in child's family? (Father/Mother/Guardian/Sibling bucket)
    df["perp_in_child_family"] = np.where(
        df["perp_relationship"].isin(allowed_relationships), "Y", "N"
    )

    # 2) Attach primary address and compute address reoccurrence flag
    #    (same primary address across >1 referral for same long_person_id + person_id)
    add_prim = df_add.copy()
    add_prim = add_prim[add_prim["Address Type"].str.lower() == "primary"]
    add_prim = add_prim[["Referral ID", "Address Line 1", "City", "Zip Code"]].drop_duplicates()

    df = df.merge(
        add_prim,
        left_on="referral_id",
        right_on="Referral ID",
        how="left",
    )

    # Build a simple address key
    df["address_key"] = (
        df["Address Line 1"].fillna("").str.upper().str.strip()
        + "|"
        + df["City"].fillna("").str.upper().str.strip()
        + "|"
        + df["Zip Code"].fillna("").astype(str).str.strip()
    )
    df.loc[df["Address Line 1"].isna(), "address_key"] = np.nan

    # Within same child (long_person_id, person_id) and same address, if there is more
    # than one distinct referral_id => address exact match reoccurrence.
    mask = df["address_key"].notna() & (df["address_key"] != "")
    counts = (
        df.loc[mask]
          .groupby(["long_person_id", "person_id", "address_key"])["referral_id"]
          .transform("nunique")
    )
    df["address_exact_match_flag"] = "N"
    df.loc[mask & (counts > 1), "address_exact_match_flag"] = "Y"

    return df


# -------------------------------------------------------------------
# SUMMARIES
#   1) At (referral_id, person_id, allegation_id) level
#   2) At (referral_id, person_id) level
#
# For each level:
#   1. Perp in child's family: Y / N counts
#   2. Out of Y: reoccurrence_flag Y / N counts
#   3. Out of N: address_exact_match_flag Y / N and final match Y / N
# -------------------------------------------------------------------

def build_grain_summaries(df_annot):
    # -------- Level 1: referral_id + person_id + allegation_id --------
    lvl1 = (
        df_annot
        .groupby(["referral_id", "person_id", "allegation_id"], as_index=False)
        .agg(
            perp_in_child_family=("perp_in_child_family",
                                  lambda s: "Y" if (s == "Y").any() else "N"),
            perp_reoccurrence_flag=("perp_reoccurrence_flag",
                                    lambda s: "Y" if (s == "Y").any() else "N"),
            address_exact_match_flag=("address_exact_match_flag",
                                      lambda s: "Y" if (s == "Y").any() else "N"),
        )
    )

    # 1. Perp in child's family: Y / N counts
    lvl1_family_counts = (
        lvl1["perp_in_child_family"]
        .value_counts()
        .rename_axis("perp_in_child_family")
        .reset_index(name="count")
    )

    # 2. Out of Y: reoccurrence_flag Y / N
    lvl1_family_yes = lvl1[lvl1["perp_in_child_family"] == "Y"]
    lvl1_family_yes_match_counts = (
        lvl1_family_yes["perp_reoccurrence_flag"]
        .value_counts()
        .rename_axis("perp_reoccurrence_flag")
        .reset_index(name="count")
    )

    # 3. Out of N: address_exact_match_flag Y / N and final match Y / N
    lvl1_family_no = lvl1[lvl1["perp_in_child_family"] == "N"]

    lvl1_nonfam_addr_counts = (
        lvl1_family_no["address_exact_match_flag"]
        .value_counts()
        .rename_axis("address_exact_match_flag")
        .reset_index(name="count")
    )

    lvl1_nonfam_final_match_counts = (
        lvl1_family_no["perp_reoccurrence_flag"]
        .value_counts()
        .rename_axis("perp_reoccurrence_flag")
        .reset_index(name="count")
    )

    # -------- Level 2: referral_id + person_id --------
    lvl2 = (
        df_annot
        .groupby(["referral_id", "person_id"], as_index=False)
        .agg(
            perp_in_child_family=("perp_in_child_family",
                                  lambda s: "Y" if (s == "Y").any() else "N"),
            perp_reoccurrence_flag=("perp_reoccurrence_flag",
                                    lambda s: "Y" if (s == "Y").any() else "N"),
            address_exact_match_flag=("address_exact_match_flag",
                                      lambda s: "Y" if (s == "Y").any() else "N"),
        )
    )

    lvl2_family_counts = (
        lvl2["perp_in_child_family"]
        .value_counts()
        .rename_axis("perp_in_child_family")
        .reset_index(name="count")
    )

    lvl2_family_yes = lvl2[lvl2["perp_in_child_family"] == "Y"]
    lvl2_family_yes_match_counts = (
        lvl2_family_yes["perp_reoccurrence_flag"]
        .value_counts()
        .rename_axis("perp_reoccurrence_flag")
        .reset_index(name="count")
    )

    lvl2_family_no = lvl2[lvl2["perp_in_child_family"] == "N"]

    lvl2_nonfam_addr_counts = (
        lvl2_family_no["address_exact_match_flag"]
        .value_counts()
        .rename_axis("address_exact_match_flag")
        .reset_index(name="count")
    )

    lvl2_nonfam_final_match_counts = (
        lvl2_family_no["perp_reoccurrence_flag"]
        .value_counts()
        .rename_axis("perp_reoccurrence_flag")
        .reset_index(name="count")
    )

    return {
        "lvl1_table": lvl1,
        "lvl1_family_counts": lvl1_family_counts,
        "lvl1_family_yes_match_counts": lvl1_family_yes_match_counts,
        "lvl1_nonfam_addr_counts": lvl1_nonfam_addr_counts,
        "lvl1_nonfam_final_match_counts": lvl1_nonfam_final_match_counts,
        "lvl2_table": lvl2,
        "lvl2_family_counts": lvl2_family_counts,
        "lvl2_family_yes_match_counts": lvl2_family_yes_match_counts,
        "lvl2_nonfam_addr_counts": lvl2_nonfam_addr_counts,
        "lvl2_nonfam_final_match_counts": lvl2_nonfam_final_match_counts,
    }


# -------------------------------------------------------------------
# EXAMPLE USAGE
# -------------------------------------------------------------------
# df      = your main longitudinal-perp dataframe
# df_rel  = relatives table
# df_add  = address table

# 1) Run the matching logic (you already did this step successfully):
# df_with_flag = add_perp_reoccurrence_flag(df, df_rel, df_add)

# 2) Add derived flags & build summaries:
# df_annot = add_perp_in_family_and_address_flags(df_with_flag, df_add)
# summaries = build_grain_summaries(df_annot)

# For example:
# print("LEVEL 1 – perp in child's family (Y/N):")
# print(summaries["lvl1_family_counts"])
#
# print("LEVEL 1 – out of family=Y, reoccurrence Y/N:")
# print(summaries["lvl1_family_yes_match_counts"])
#
# print("LEVEL 1 – out of family=N, address exact match Y/N:")
# print(summaries["lvl1_nonfam_addr_counts"])
#
# print("LEVEL 1 – out of family=N, final match Y/N:")
# print(summaries["lvl1_nonfam_final_match_counts"])
#
# Same pattern for LEVEL 2 using the lvl2_* keys.

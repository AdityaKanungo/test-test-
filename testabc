import numpy as np
from collections import defaultdict
from itertools import combinations

# -------------------------------------------------------------------
# union–find (for strong matches and for likely match propagation)
# -------------------------------------------------------------------
class DisjointSet:
    def __init__(self, n):
        self.parent = list(range(n))
        self.rank = [0] * n

    def find(self, x):
        while self.parent[x] != x:
            self.parent[x] = self.parent[self.parent[x]]
            x = self.parent[x]
        return x

    def union(self, a, b):
        pa, pb = self.find(a), self.find(b)
        if pa == pb:
            return
        if self.rank[pa] < self.rank[pb]:
            pa, pb = pb, pa
        self.parent[pb] = pa
        if self.rank[pa] == self.rank[pb]:
            self.rank[pa] += 1


# -------------------------------------------------------------------
# MAIN FUNCTION with Option B implemented
# -------------------------------------------------------------------
def build_longitudinal_dataset(df):

    df = df.copy()
    n = len(df)

    # Assign a stable row index
    df["ROW_ID"] = np.arange(n, dtype=int)

    # Ensure required columns exist
    for col in ["matched_pair", "matched_rule", 
                "likely_matched_pair", "likely_matched_rule",
                "LONG_PERSON_ID"]:
        if col not in df.columns:
            df[col] = ""

    # NumPy arrays (fast)
    FN  = df["FN"].to_numpy(object)
    LN  = df["LN"].to_numpy(object)
    DOB = df["DOB"].to_numpy(object)
    SSN = df["SSN"].to_numpy(object)
    ref_ids = df["referral_id"].to_numpy(object)

    matched_pair  = df["matched_pair"].to_numpy(object)
    matched_rule  = df["matched_rule"].to_numpy(object)
    likely_pair   = df["likely_matched_pair"].to_numpy(object)
    likely_rule   = df["likely_matched_rule"].to_numpy(object)
    long_person   = df["LONG_PERSON_ID"].to_numpy(object)

    # ----------------------------------------------------------------
    # 1) Strong Matches (SSN) — union–find for LONG_PERSON_ID
    # ----------------------------------------------------------------
    dsu = DisjointSet(n)

    ssn_groups = defaultdict(list)
    for i, ssn in enumerate(SSN):
        if ssn and str(ssn).strip() != "":
            ssn_groups[ssn].append(i)

    for ssn, idxs in ssn_groups.items():
        if len(idxs) < 2:
            continue

        for i, j in combinations(idxs, 2):
            r1 = (FN[i], LN[i], DOB[i], SSN[i])
            r2 = (FN[j], LN[j], DOB[j], SSN[j])
            rule = match_rule(r1, r2)

            if rule is None:
                continue

            # Record matched pairs
            matched_pair[i] += f"{ref_ids[j]};"
            matched_rule[i] += f"{rule};"
            matched_pair[j] += f"{ref_ids[i]};"
            matched_rule[j] += f"{rule};"

            # Union strong matches
            dsu.union(i, j)

    # Assign LONG_PERSON_ID
    root_to_id = {}
    next_id = 1
    for i in range(n):
        root = dsu.find(i)
        if root not in root_to_id:
            root_to_id[root] = next_id
            next_id += 1
        long_person[i] = root_to_id[root]

    # ----------------------------------------------------------------
    # 2) Likely Matches (block-based)
    # ----------------------------------------------------------------
    blocks = [
        ["FN", "LN", "DOB"],
        ["FN", "LN"],
        ["FN", "DOB"],
        ["LN", "DOB"],
    ]

    pairs_seen = set()
    likely_edges = []     # store (i, j, rule) to later propagate transitively

    for cols in blocks:
        key_arrays = [df[c].to_numpy(object) for c in cols]

        groups = defaultdict(list)
        for i in range(n):
            key = tuple(arr[i] for arr in key_arrays)
            groups[key].append(i)

        for idxs in groups.values():
            if len(idxs) < 2:
                continue
            for i, j in combinations(idxs, 2):
                if i > j:
                    i, j = j, i

                if (i, j) in pairs_seen:
                    continue
                pairs_seen.add((i, j))

                r1 = (FN[i], LN[i], DOB[i], SSN[i])
                r2 = (FN[j], LN[j], DOB[j], SSN[j])
                rule = likely_match_rule(r1, r2)

                if rule is None:
                    continue

                # Record direct likely match
                likely_pair[i] += f"{ref_ids[j]};"
                likely_rule[i] += f"{rule};"
                likely_pair[j] += f"{ref_ids[i]};"
                likely_rule[j] += f"{rule};"

                likely_edges.append((i, j, rule))

    # ----------------------------------------------------------------
    # 3) OPTION B — Likely Match Transitive Propagation
    # ----------------------------------------------------------------
    # Build a second union–find just for likely match components
    dsu_likely = DisjointSet(n)

    for i, j, rule in likely_edges:
        dsu_likely.union(i, j)

    # Build clusters: root → list of indices
    likely_clusters = defaultdict(list)
    for i in range(n):
        root = dsu_likely.find(i)
        likely_clusters[root].append(i)

    # For each cluster, generate full pairwise closure
    for root, idxs in likely_clusters.items():
        if len(idxs) < 3:
            continue   # no need to add closure for 1–2 items

        for i, j in combinations(idxs, 2):
            i_ref = ref_ids[i]
            j_ref = ref_ids[j]

            # Avoid double-appending
            if f"{j_ref};" not in likely_pair[i]:
                likely_pair[i] += f"{j_ref};"
            if f"{i_ref};" not in likely_pair[j]:
                likely_pair[j] += f"{i_ref};"

            # Use special rule code to indicate "transitive likely match"
            # You can change this if you want
            if "TRANS" not in likely_rule[i]:
                likely_rule[i] += "TRANS;"
            if "TRANS" not in likely_rule[j]:
                likely_rule[j] += "TRANS;"

    # ----------------------------------------------------------------
    # 4) Clean output columns
    # ----------------------------------------------------------------
    trim = lambda arr: np.char.rstrip(arr.astype(str), ";")

    df["matched_pair"] = trim(matched_pair)
    df["matched_rule"] = trim(matched_rule)
    df["likely_matched_pair"] = trim(likely_pair)
    df["likely_matched_rule"] = trim(likely_rule)
    df["LONG_PERSON_ID"] = long_person

    return df

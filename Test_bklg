Got it — you want basic EDA before any matching is done (pre-match), focusing ONLY on the 4 input fields:

1️⃣ First Name (FN)

2️⃣ Last Name (LN)

3️⃣ Date of Birth (DOB)

4️⃣ SSN

No matching fields.
No longitudinal fields.
Just EDA on the four raw identifying fields.

Here is clean, ready-to-run code for descriptive statistics + visualisations for FN, LN, DOB, SSN.


---

✅ PRE-MATCH EDA CODE FOR FN, LN, DOB, SSN

Assume your dataframe is named df and contains columns:

["FN", "LN", "DOB", "SSN"]


---

1. Basic Completeness & Structure

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Replace blanks with NaN for analysis
df["FN_clean"]  = df["FN"].replace(["", " ", None], np.nan)
df["LN_clean"]  = df["LN"].replace(["", " ", None], np.nan)
df["SSN_clean"] = df["SSN"].replace(["", " ", None, "nan", "NaN"], np.nan)

# DOB already NaT for blanks
df["DOB_clean"] = pd.to_datetime(df["DOB"], errors="coerce")


---

2. Missingness Summary

missing_summary = pd.DataFrame({
    "Missing (%)": [
        df["FN_clean"].isna().mean()*100,
        df["LN_clean"].isna().mean()*100,
        df["DOB_clean"].isna().mean()*100,
        df["SSN_clean"].isna().mean()*100,
    ]
}, index=["FN", "LN", "DOB", "SSN"])

print("Missingness Summary:\n")
print(missing_summary)


---

3. Uniqueness / Cardinality

uniqueness_summary = pd.DataFrame({
    "Unique Values": [
        df["FN_clean"].nunique(dropna=True),
        df["LN_clean"].nunique(dropna=True),
        df["DOB_clean"].nunique(dropna=True),
        df["SSN_clean"].nunique(dropna=True),
    ]
}, index=["FN", "LN", "DOB", "SSN"])

print("\nUniqueness Summary:\n")
print(uniqueness_summary)


---

4. Frequency tables (Top 20)

Useful for spotting typos or inconsistent spellings.

print("\nTop First Names:")
print(df["FN_clean"].value_counts().head(20))

print("\nTop Last Names:")
print(df["LN_clean"].value_counts().head(20))

print("\nTop DOBs:")
print(df["DOB_clean"].value_counts().head(20))

print("\nTop SSNs:")
print(df["SSN_clean"].value_counts().head(20))


---

5. Visualizations


---

5.1 Missingness Bar Chart

missing_summary.plot(kind="bar", figsize=(6,4), legend=False)
plt.title("Missingness % by Field")
plt.ylabel("Percent Missing")
plt.show()


---

5.2 Distribution of DOB

df["DOB_clean"].dropna().hist(bins=50, figsize=(8,4))
plt.title("Distribution of Date of Birth")
plt.xlabel("Year")
plt.ylabel("Count")
plt.show()


---

5.3 Top 15 First Names

df["FN_clean"].value_counts().head(15).plot(kind="bar", figsize=(8,4))
plt.title("Top 15 Most Frequent First Names")
plt.xlabel("First Name")
plt.ylabel("Count")
plt.xticks(rotation=45)
plt.show()


---

5.4 Top 15 Last Names

df["LN_clean"].value_counts().head(15).plot(kind="bar", figsize=(8,4))
plt.title("Top 15 Most Frequent Last Names")
plt.xlabel("Last Name")
plt.ylabel("Count")
plt.xticks(rotation=45)
plt.show()


---

5.5 SSN Completeness Pie Chart

ssn_counts = df["SSN_clean"].isna().value_counts()
ssn_counts.index = ["Missing SSN", "Valid SSN"]

ssn_counts.plot(kind="pie", autopct="%1.1f%%", figsize=(6,6))
plt.title("SSN Completeness")
plt.ylabel("")
plt.show()


---

6. Optional: Character Length EDA

Useful for identifying typos.

df["FN_len"] = df["FN_clean"].dropna().apply(len)
df["LN_len"] = df["LN_clean"].dropna().apply(len)
df["SSN_len"] = df["SSN_clean"].dropna().apply(len)

df[["FN_len","LN_len","SSN_len"]].describe()


---

⭐ You now have a complete Pre-Match EDA Suite

This helps you understand:

How messy the data is

Whether blanks & duplicates will affect match quality

Variations in FN/LN spellings

Patterns in DOB distribution

SSN completeness

Any anomalies before running the matcher


If you'd like, I can also generate:

✔️ A leadership-friendly summary

✔️ Slide-ready visuals

✔️ Automated fuzzy-cleaning suggestions

✔️ Statistical validation of match confidence

Just tell me!
